<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Erika Marangi" />
    
    <link rel="shortcut icon" type="image/x-icon" href="/img/favicon.ico">
    <title>Project 2</title>
    <meta name="generator" content="Hugo 0.79.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="/"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="/post/">BLOG</a></li>
        
        <li><a href="/projects/">PROJECTS</a></li>
        
        <li><a href="/resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="/project/project2/">Project 2</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<h1>
Introduction Paragraph
<h1>
<h4>
<p>For my project 2, I decided to use the combined data from my first project to look at the correlation between different variables a little more closely. My data is about different professional basketball players, their rank, their team, the position they play, their injuries, how many games they missed due to their injuries, and how much money they made per game they missed. My data has 8 variables and 91 observations for each variable.</p>
<h1>
<p>Part 1: MANOVA</p>
<pre class="r"><code>class_diag &lt;- function(probs, truth) {
    # CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
    tab &lt;- table(factor(probs &gt; 0.5, levels = c(&quot;FALSE&quot;, &quot;TRUE&quot;)), 
        truth)
    acc = sum(diag(tab))/sum(tab)
    sens = tab[2, 2]/colSums(tab)[2]
    spec = tab[1, 1]/colSums(tab)[1]
    ppv = tab[2, 2]/rowSums(tab)[2]
    f1 = 2 * (sens * ppv)/(sens + ppv)
    
    if (is.numeric(truth) == FALSE &amp; is.logical(truth) == FALSE) 
        truth &lt;- as.numeric(truth) - 1
    
    # CALCULATE EXACT AUC
    ord &lt;- order(probs, decreasing = TRUE)
    probs &lt;- probs[ord]
    truth &lt;- truth[ord]
    
    TPR = cumsum(truth)/max(1, sum(truth))
    FPR = cumsum(!truth)/max(1, sum(!truth))
    
    dup &lt;- c(probs[-1] &gt;= probs[-length(probs)], FALSE)
    TPR &lt;- c(0, TPR[!dup], 1)
    FPR &lt;- c(0, FPR[!dup], 1)
    n &lt;- length(TPR)
    auc &lt;- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))
    
    data.frame(acc, sens, spec, ppv, f1, auc)
}

library(tidyverse)
finaldataproject2 &lt;- read.csv(&quot;project2data.csv&quot;)
finaldataproject2 &lt;- na.omit(finaldataproject2)
finaldataproject2 &lt;- finaldataproject2 %&gt;% select(-Player.Rank)
man1 &lt;- manova(cbind(Games.Missed, Cash.Earned.Per.Game, Player.Rank.1) ~ 
    Injury, data = finaldataproject2)
summary(man1)</code></pre>
<pre><code>##           Df  Pillai approx F num Df den Df Pr(&gt;F)
## Injury    18 0.51328  0.82563     54    216 0.7962
## Residuals 72</code></pre>
<pre class="r"><code>summary.aov(man1)</code></pre>
<pre><code>##  Response Games.Missed :
##             Df  Sum Sq Mean Sq F value Pr(&gt;F)
## Injury      18  6374.4  354.13  1.2464   0.25
## Residuals   72 20456.9  284.12               
## 
##  Response Cash.Earned.Per.Game :
##             Df     Sum Sq    Mean Sq F value Pr(&gt;F)
## Injury      18 5.6405e+11 3.1336e+10  0.3676   0.99
## Residuals   72 6.1380e+12 8.5250e+10               
## 
##  Response Player.Rank.1 :
##             Df Sum Sq Mean Sq F value Pr(&gt;F)
## Injury      18  13789  766.07  0.9034 0.5766
## Residuals   72  61057  848.02</code></pre>
<h4>
<p>The summary from my MANOVA test gave me a Pillai value of 0.51328, an F value of 0.82563, and a P-value of 0.7962. Because the P-value is greater than .05, I can not reject the null hypothesis that declares that the number of games missed, the cash earned for each missed game, and the players rank have a mean difference based on which Injury a player endured. If the p-value had been less than .05 and was significant, I would then run a univariate ANOVA and post-Hoc t-tests to see which individual variables are significant and their influence on the type of injury.</p>
<h1>
<p>Part 2: Randomization Test</p>
<pre class="r"><code>library(vegan)
dists &lt;- finaldataproject2 %&gt;% select(Cash.Earned.Per.Game) %&gt;% 
    dist
adonis(dists ~ Injury, data = finaldataproject2)</code></pre>
<pre><code>## 
## Call:
## adonis(formula = dists ~ Injury, data = finaldataproject2) 
## 
## Permutation: free
## Number of permutations: 999
## 
## Terms added sequentially (first to last)
## 
##           Df  SumsOfSqs    MeanSqs F.Model      R2 Pr(&gt;F)
## Injury    18 5.6405e+11 3.1336e+10 0.36758 0.08416    0.9
## Residuals 72 6.1380e+12 8.5250e+10         0.91584       
## Total     90 6.7020e+12                    1.00000</code></pre>
<pre class="r"><code>finaldataproject2 %&gt;% group_by(Injury) %&gt;% summarize(means = mean(Cash.Earned.Per.Game)) %&gt;% 
    summarize(mean_diff = diff(means))</code></pre>
<pre><code>## # A tibble: 18 x 1
##    mean_diff
##        &lt;dbl&gt;
##  1   194580.
##  2  -250335.
##  3   -36607.
##  4   113557.
##  5   -53597.
##  6   134035.
##  7   -69311.
##  8   127340.
##  9   -18683.
## 10   -64977.
## 11   -24917.
## 12   -43204.
## 13   125483.
## 14    75774.
## 15  -195769.
## 16     9065.
## 17   205995 
## 18  -103959.</code></pre>
<pre class="r"><code>randdist &lt;- vector()
for (i in 1:5000) {
    new &lt;- data.frame(CashEarned = sample(finaldataproject2$Cash.Earned.Per.Game), 
        Injury = finaldataproject2$Injury)
    randdist[i] &lt;- mean(new[new$Injury == c(&quot;Foot&quot;, &quot;Thigh&quot;, 
        &quot;Ankle&quot;), ]$CashEarned) - mean(new[new$Injury == c(&quot;Elbow&quot;, 
        &quot;Wrist&quot;, &quot;Shoulder&quot;), ]$CashEarned)
}
{
    hist(randdist, main = &quot;&quot;, ylab = &quot;&quot;)
}</code></pre>
<img src="/project/project2_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" />
<h4>
<p>For my randomization test (PERMANOVA), I first calculated the euclidean distances between all of the different player rankings and cash earned per game. Then, I ran this through the adonis function for the distance matrix. The R2 statistic is important because it explains what percent of the variation in distances is explained by the group being tested. The null hypothesis states that there is no variation in distance between the variables. This null hypothesis is not rejected because the p-value is much larger than .05 ( 0.923). Then, I found the mean-diffs for my data looking at Injury and Cash Earned, and graphed the distribution.The graph is centered without any extreme skew.</p>
<H1>
<p>Part 3: Linear Regression</p>
<pre class="r"><code>scaled &lt;- finaldataproject2 %&gt;% mutate(PerGameScaled = scale(Cash.Earned.Per.Game))
scaled &lt;- scaled %&gt;% mutate(MissedScaled = scale(Games.Missed))
scaled &lt;- scaled %&gt;% mutate(PlayerScale = scale(Player.Rank.1))
scalefit &lt;- lm(PerGameScaled ~ PlayerScale + MissedScaled, data = scaled)
fit &lt;- lm(Cash.Earned.Per.Game ~ Player.Rank.1 + Games.Missed, 
    data = finaldataproject2)
summary(fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Cash.Earned.Per.Game ~ Player.Rank.1 + Games.Missed, 
##     data = finaldataproject2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -384627  -95859  -45332   47888 1775725 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   419174.1    61426.1   6.824 1.08e-09 ***
## Player.Rank.1  -2918.6      965.0  -3.024  0.00327 ** 
## Games.Missed    -174.9     1611.8  -0.108  0.91385    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 262600 on 88 degrees of freedom
## Multiple R-squared:  0.09454,    Adjusted R-squared:  0.07396 
## F-statistic: 4.594 on 2 and 88 DF,  p-value: 0.01265</code></pre>
<pre class="r"><code>summary(scalefit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = PerGameScaled ~ PlayerScale + MissedScaled, data = scaled)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.4095 -0.3513 -0.1661  0.1755  6.5072 
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)   1.185e-16  1.009e-01   0.000  1.00000   
## PlayerScale  -3.084e-01  1.020e-01  -3.024  0.00327 **
## MissedScaled -1.106e-02  1.020e-01  -0.108  0.91385   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9623 on 88 degrees of freedom
## Multiple R-squared:  0.09454,    Adjusted R-squared:  0.07396 
## F-statistic: 4.594 on 2 and 88 DF,  p-value: 0.01265</code></pre>
<h4>
<p>I ran a linear regression looking at how the Player’s rank and the number of games missed effect the amount of money earned per game. If a player was ranked (0), and missed (0) games,they would make a predicted 419174.10 per game they missed. For each increase in player rank (meaning a “lower” rank) they would make 2918.6 less when the number of games missed is held constant. If the number of games missed increases by one, then the amount of money earned will decrease by 174.9 when player rank is held constant. I also ran the same regression with the numeric variables scaled, and go the same significant variable, “player rank.”</p>
<pre class="r"><code>library(lmtest)
library(ggplot2)
library(sandwich)
fit2 &lt;- lm(Cash.Earned.Per.Game ~ Player.Rank.1 * Games.Missed, 
    data = finaldataproject2)
summary(fit2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Cash.Earned.Per.Game ~ Player.Rank.1 * Games.Missed, 
##     data = finaldataproject2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -375255  -93746  -36645   46913 1775943 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                404860.91   71593.68   5.655 1.95e-07 ***
## Player.Rank.1               -2595.05    1269.86  -2.044    0.044 *  
## Games.Missed                  704.39    2754.82   0.256    0.799    
## Player.Rank.1:Games.Missed    -21.55      54.62  -0.395    0.694    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 263900 on 87 degrees of freedom
## Multiple R-squared:  0.09616,    Adjusted R-squared:  0.06499 
## F-statistic: 3.085 on 3 and 87 DF,  p-value: 0.03141</code></pre>
<pre class="r"><code>ggplot(finaldataproject2, aes(x = Player.Rank.1, y = Games.Missed)) + 
    geom_point(aes(color = Cash.Earned.Per.Game)) + geom_smooth(method = &quot;lm&quot;, 
    formula = y ~ 1, se = F, fullrange = T, aes(color = Cash.Earned.Per.Game))</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>bptest(fit2)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  fit2
## BP = 1.7159, df = 3, p-value = 0.6334</code></pre>
<pre class="r"><code>summary(fit2)$coef[, 1:2]</code></pre>
<pre><code>##                                Estimate  Std. Error
## (Intercept)                404860.90999 71593.68462
## Player.Rank.1               -2595.05221  1269.86381
## Games.Missed                  704.39320  2754.81654
## Player.Rank.1:Games.Missed    -21.55155    54.62103</code></pre>
<pre class="r"><code>coeftest(fit2, vcov = vcovHC(fit2))[, 1:2]</code></pre>
<pre><code>##                                Estimate  Std. Error
## (Intercept)                404860.90999 75276.70056
## Player.Rank.1               -2595.05221   842.69611
## Games.Missed                  704.39320  1844.54585
## Player.Rank.1:Games.Missed    -21.55155    24.85014</code></pre>
<pre class="r"><code>resids &lt;- fit2$residuals
ks.test(resids, &quot;pnorm&quot;, mean = 0, sd(resids))</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  resids
## D = 0.2446, p-value = 2.798e-05
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>shapiro.test(resids)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resids
## W = 0.54696, p-value = 2.646e-15</code></pre>
<h4>
<p>There is not a lot of fanning on the scatterplot so I can not tell if there is a standard error from looking at that. I ran a Breusch-Pagan test to test for homoskedasticity. The null hypothesis states that homoskedasticity is present, and because the p-value is 0.6334, we fail to reject the null hypothesis. I then ran a test for the uncorrected standard error, and another for the corrected standard errors.After the correction , the standard errors for each of my predictor variables decreased. When I tested the normality of my data, the p-value was less than .05, so I reject the null hypothesis that the true distribution of the data is normal. From the summary of my linear regression, I see that the R-squared value is 0.09616, which is the proportion of variation in the response variable (Cash Earned per Game) explained by the overall model.</p>
<H1>
<p>Part 4: Bootstrapping</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
fit3 &lt;- lm(Cash.Earned.Per.Game ~ Player.Rank.1 * Games.Missed, 
    data = finaldataproject2)
summary(fit3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Cash.Earned.Per.Game ~ Player.Rank.1 * Games.Missed, 
##     data = finaldataproject2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -375255  -93746  -36645   46913 1775943 
## 
## Coefficients:
##                             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                404860.91   71593.68   5.655 1.95e-07 ***
## Player.Rank.1               -2595.05    1269.86  -2.044    0.044 *  
## Games.Missed                  704.39    2754.82   0.256    0.799    
## Player.Rank.1:Games.Missed    -21.55      54.62  -0.395    0.694    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 263900 on 87 degrees of freedom
## Multiple R-squared:  0.09616,    Adjusted R-squared:  0.06499 
## F-statistic: 3.085 on 3 and 87 DF,  p-value: 0.03141</code></pre>
<pre class="r"><code>boot_dat &lt;- sample_frac(finaldataproject2, replace = T)
samp_distn &lt;- replicate(5000, {
    boot_dat &lt;- sample_frac(finaldataproject2, replace = T)
    fitnew &lt;- lm(Cash.Earned.Per.Game ~ Player.Rank.1 * Games.Missed, 
        data = boot_dat)
    coef(fitnew)
})
samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) Player.Rank.1 Games.Missed Player.Rank.1:Games.Missed
## 1    74914.15      864.4534     2012.965                   27.68555</code></pre>
<pre class="r"><code>samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% pivot_longer(1:3) %&gt;% 
    group_by(name) %&gt;% summarize(lower = quantile(value, 0.025), 
    upper = quantile(value, 0.975))</code></pre>
<pre><code>## # A tibble: 3 x 3
##   name            lower   upper
##   &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)   278695. 572264.
## 2 Games.Missed   -4002.   3918.
## 3 Player.Rank.1  -4484.  -1034.</code></pre>
<h4>
<p>To bootstrap my data, I sampled my data with replacement and calculated the coefficient estimates for my new bootstrapped sample. The standard deviations of these estimates are my new standard error. The standard error for player rank was 854.363, for games missed 2029.967, and for the interaction the error was 27.19456. Because the standard error for the bootstrapped data is so high, it means that my data is not normalized and irregular. I also calculated the 95% confidence interval of my predictor variables.</p>
<pre class="r"><code>fit4 &lt;- lm(Cash.Earned.Per.Game ~ Games.Missed * Player.Rank.1, 
    data = finaldataproject2)
resids &lt;- fit4$residuals
fitted &lt;- fit4$fitted.values
residsamp &lt;- replicate(5000, {
    newresids &lt;- sample(resids, replace = TRUE)
    finaldataproject2$new_y &lt;- fitted + newresids
    fit4 &lt;- lm(new_y ~ Games.Missed * Player.Rank.1, data = finaldataproject2)
    coef(fit4)
})
residsamp %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept) Games.Missed Player.Rank.1 Games.Missed:Player.Rank.1
## 1    69194.12     2701.285      1212.225                   53.49122</code></pre>
<h4>
<p>I also calculated the bootstrap residuals for my data which resulted in larger estimates for most of the variables.</p>
<h1>
<p>Part 5: Binary Regression</p>
<pre class="r"><code>newdata &lt;- finaldataproject2 %&gt;% mutate(Player.Rank.1 = case_when(Player.Rank.1 &lt;= 
    50 ~ &quot;Top&quot;, Player.Rank.1 &lt;= 100 ~ &quot;Bottom&quot;))
newdata &lt;- newdata %&gt;% data.frame(RankBottom = ifelse(newdata$Player.Rank.1 == 
    &quot;Bottom&quot;, 1, 0), RankTop = ifelse(newdata$Player.Rank.1 == 
    &quot;Top&quot;, 1, 0))
fitnew &lt;- glm(RankTop ~ Games.Missed + Cash.Earned.Per.Game, 
    data = newdata, family = binomial(link = &quot;logit&quot;))
coeftest(fitnew)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                         Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)          -1.9032e+00  5.4362e-01 -3.5010 0.0004635 ***
## Games.Missed          3.3897e-03  1.5374e-02  0.2205 0.8254930    
## Cash.Earned.Per.Game  8.4709e-06  2.1211e-06  3.9935 6.509e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<h4>
<p>First, I created a binary variable from my player rankings. The top players are the top half and the bottom players are the bottom half rank. Then, I ran a regression looking at how the number of games missed and the cash earned per game can predict which level of rank a player is at. By looking at the regression, both the number of games missed and the amount of cash earned increase the odds of a player being ranked in the top bracket, yet only the amount of cash earned is significant. The log odds of being ranked in the top is -1.5204 and the odds of this is 0.2186244. For each game missed, the log odds of being ranked a top player are -1.5204+7.7699e-03 or -1.51263 and the odds are 0.2203297. For each increase in amount of cash earned the log odds of being ranked a top player are -1.5204+2.9107e-06 or -1.520397, and the odds are 0.2186251.</p>
<pre class="r"><code>library(plotROC)
probs &lt;- predict(fitnew, type = &quot;response&quot;)
table(predict = as.numeric(probs &gt; 0.5), truth = newdata$RankTop) %&gt;% 
    addmargins()</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0   31 12  43
##     1   11 37  48
##     Sum 42 49  91</code></pre>
<pre class="r"><code>ROC &lt;- ggplot(newdata) + geom_roc(aes(d = RankTop, m = probs), 
    n.cuts = 0)
ROC</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROC)</code></pre>
<pre><code>##   PANEL group      AUC
## 1     1    -1 0.797862</code></pre>
<pre class="r"><code>newdata$logit &lt;- predict(fitnew, type = &quot;link&quot;)
newdata %&gt;% ggplot(aes(logit, color = Player.Rank.1, fill = Player.Rank.1)) + 
    geom_density(alpha = 0.4) + theme(legend.position = c(0.85, 
    0.85)) + geom_vline(xintercept = 0) + xlab(&quot;predictor (logit)&quot;)</code></pre>
<img src="/project/project2_files/figure-html/unnamed-chunk-8-2.png" width="672" style="display: block; margin: auto;" />
<h4>
<p>After calculating the confusion matrix for this data, I found that the sensitivity or true positive rate was 0.1875 and the specificity or true negative rate was 0.9322. The precision for my regression was 0.6. After creating an ROC curve and calculating the AUC, I can conclude that the AUC (0.7868114) is considered “fair.” Next, I made a density plot of the log odds and grouped it by the outcome variable (top or bottom rank of players).</p>
<h1>
<p>Part 6: Final Regression</p>
<pre class="r"><code>library(plotROC)
library(glmnet)
library(lmtest)
finalfit &lt;- glm(RankTop ~ Position + Injury + Games.Missed + 
    Cash.Earned + Team + Cash.Earned.Per.Game, data = newdata, 
    family = binomial(link = &quot;logit&quot;))
coeftest(finalfit)</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                         Estimate  Std. Error z value Pr(&gt;|z|)
## (Intercept)           2.6184e+02  4.1431e+05  0.0006   0.9995
## PositionPF            8.6998e+01  1.2616e+05  0.0007   0.9994
## PositionPG           -2.6603e+01  8.0346e+04 -0.0003   0.9997
## PositionSF            1.2469e+02  9.2719e+04  0.0013   0.9989
## PositionSG            1.3935e+02  1.1351e+05  0.0012   0.9990
## InjuryBack            2.0992e+02  3.8605e+05  0.0005   0.9996
## InjuryCalf            1.0006e+01  9.3599e+05  0.0000   1.0000
## InjuryConcussion      8.3551e-01  4.7457e+07  0.0000   1.0000
## InjuryElbow           1.6400e+01  3.2170e+05  0.0001   1.0000
## InjuryFoot            1.8447e+02  5.7778e+05  0.0003   0.9997
## InjuryForearm        -1.4905e+02  5.4656e+05 -0.0003   0.9998
## InjuryGroin          -1.0525e+02  1.4451e+05 -0.0007   0.9994
## InjuryHamstring      -1.1332e+02  6.5763e+05 -0.0002   0.9999
## InjuryHeel            4.1482e+01  1.9769e+05  0.0002   0.9998
## InjuryIllness        -1.7355e+02  1.4050e+05 -0.0012   0.9990
## InjuryKnee            5.2625e+01  4.8786e+04  0.0011   0.9991
## InjuryLeg             6.2746e+02  6.2533e+05  0.0010   0.9992
## InjuryNeck            7.7211e+01  4.8083e+05  0.0002   0.9999
## InjuryPersonal       -1.0437e+02  1.2794e+05 -0.0008   0.9993
## InjuryShoulder        2.4951e+02  4.4050e+05  0.0006   0.9995
## InjuryThigh          -7.7129e+01  4.7453e+07  0.0000   1.0000
## InjuryThumb           4.9527e+01  3.6074e+05  0.0001   0.9999
## InjuryWrist           2.0722e+02  5.7569e+05  0.0004   0.9997
## Games.Missed         -2.7894e+01  8.6807e+03 -0.0032   0.9974
## Cash.Earned           1.0874e-04  3.0243e-02  0.0036   0.9971
##  [ reached getOption(&quot;max.print&quot;) -- omitted 28 rows ]</code></pre>
<pre class="r"><code>probs &lt;- predict(finalfit, type = &quot;response&quot;)
table(predict = as.numeric(probs &gt; 0.5), truth = newdata$RankTop) %&gt;% 
    addmargins()</code></pre>
<pre><code>##        truth
## predict  0  1 Sum
##     0   42  0  42
##     1    0 49  49
##     Sum 42 49  91</code></pre>
<pre class="r"><code>ROC2 &lt;- ggplot(newdata) + geom_roc(aes(d = RankTop, m = probs), 
    n.cuts = 0)
ROC2</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROC2)</code></pre>
<pre><code>##   PANEL group AUC
## 1     1    -1   1</code></pre>
<h4>
<p>Finally, I ran a regression to see how all of my variables can influence if a player is ranked as a top or bottom tier player. I was surprised to see that when the regression was run with all of my predictor variables, the accuracy, sensitivity, and specificity were all 100%. This is likely due to the fact that there are so many predictors for my output variable. This is also shown in the ROC plot and by the AUC which is a “perfect” 1.</p>
<pre class="r"><code>k = 10
data &lt;- newdata[sample(nrow(newdata)), ]
folds &lt;- cut(seq(1:nrow(newdata)), breaks = k, labels = F)
diags &lt;- NULL
for (i in 1:k) {
    train &lt;- data[folds != i, ]
    test &lt;- data[folds == i, ]
    fitnew$xlevels[[&quot;Injury&quot;]] &lt;- union(fitnew$xlevels[[&quot;Injury&quot;]], 
        levels(test$Injury))
    fitnew$xlevels[[&quot;Team&quot;]] &lt;- union(fitnew$xlevels[[&quot;Team&quot;]], 
        levels(test$Team))
    truth &lt;- test$RankTop
    fitnew &lt;- glm(RankTop ~ Position + Games.Missed + Cash.Earned + 
        Cash.Earned.Per.Game, data = train, family = binomial(link = &quot;logit&quot;))
    probs &lt;- predict(fitnew, newdata = test, type = &quot;response&quot;)
    diags &lt;- rbind(diags, class_diag(probs, truth))
}
summarize_all(diags, mean)</code></pre>
<pre><code>##         acc      sens   spec  ppv  f1       auc
## 1 0.6933333 0.5808333 0.7825 0.66 NaN 0.7423333</code></pre>
<h4>
<p>From the 10 fold CV, i can see that the accuracy, specificity, sensitivity, and AUC all decreased from the previous test. The Accuracy is now 0.6711111, the sensitivity is 0.6647619, the specificity is 0.735, and the AUC went from a “perfect” 1 to a “fair” 0.7861111.</p>
<pre class="r"><code>library(glmnet)
data.response &lt;- as.matrix(newdata$RankTop)
data.preds &lt;- model.matrix(RankTop ~ Position + Injury + Games.Missed + 
    Cash.Earned + Team + Cash.Earned.Per.Game, data = newdata)[, 
    -1]
cv &lt;- cv.glmnet(data.preds, data.response, family = &quot;binomial&quot;)
{
    plot(cv$glmnet.fit, &quot;lambda&quot;, label = TRUE)
    abline(v = log(cv$lambda.min))
    abline(v = log(cv$lambda.min), lty = 2)
}</code></pre>
<p><img src="/project/project2_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>cv &lt;- cv.glmnet(data.preds, data.response, family = &quot;binomial&quot;)
lassofit &lt;- glmnet(data.preds, data.response, family = &quot;binomial&quot;, 
    lambda = cv$lambda.min)
coef(lassofit)</code></pre>
<pre><code>## 53 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                 s0
## (Intercept)          -7.539251e-01
## PositionPF           -2.361258e-01
## PositionPG            .           
## PositionSF            .           
## PositionSG            .           
## InjuryBack            .           
## InjuryCalf            .           
## InjuryConcussion      .           
## InjuryElbow           .           
## InjuryFoot            .           
## InjuryForearm         .           
## InjuryGroin           .           
## InjuryHamstring       .           
## InjuryHeel            .           
## InjuryIllness        -2.662030e-02
## InjuryKnee            .           
## InjuryLeg             .           
## InjuryNeck            6.437769e-02
## InjuryPersonal        .           
## InjuryShoulder        2.906376e-01
## InjuryThigh           .           
## InjuryThumb           .           
## InjuryWrist           .           
## Games.Missed          .           
## Cash.Earned           3.777914e-08
## TeamBOS               4.422141e-01
## TeamCHA               .           
## TeamCHI               .           
## TeamCLE               .           
## TeamDAL               1.717183e-01
## TeamDEN               .           
## TeamDET               .           
## TeamGSW               .           
## TeamHOU               9.307658e-01
## TeamIND              -1.475232e-02
## TeamLAC               .           
## TeamLAL               .           
## TeamMEM               .           
## TeamMIA               .           
## TeamMIL               .           
## TeamMIN               .           
## TeamNOP               .           
## TeamNYK               .           
## TeamOKC               .           
## TeamORL              -6.954091e-01
## TeamPHI               .           
## TeamPHX               .           
## TeamPOR               .           
## TeamSAS               .           
## TeamTOR               .           
## TeamUTA               .           
## TeamWAS               .           
## Cash.Earned.Per.Game  2.951109e-06</code></pre>
<pre class="r"><code>lassoprob &lt;- predict(lassofit, data.preds, type = &quot;response&quot;)
class_diag(lassoprob, newdata$RankTop)</code></pre>
<pre><code>##         acc      sens      spec       ppv   f1      auc
## 1 0.8241758 0.8571429 0.7857143 0.8235294 0.84 0.872206</code></pre>
<h4>
<p>I ran a LASSO on the same variables as before and used Lambda min because that gave me the best results. The non-zero elements for predicting a player’s rank are PositionPF, Cash.Earned, TeamHOU, TeamORL, and Cash.Earned.Per.Game. The AUC went from being 1 to 0.8012634, which makes more sense and suggests over fitting. The sensitivity is now 0.8367347, the specificity is 0.7142857, and the accuracy is 0.7735849, which all differ from “1” in the previous test.</p>
<pre class="r"><code>## GIVE IT PREDICTED PROBS AND TRUTH LABELS (0/1), RETURNS
## VARIOUS DIAGNOSTICS

class_diag &lt;- function(probs, truth) {
    # CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
    
    if (is.character(truth) == TRUE) 
        truth &lt;- as.factor(truth)
    if (is.numeric(truth) == FALSE &amp; is.logical(truth) == FALSE) 
        truth &lt;- as.numeric(truth) - 1
    
    tab &lt;- table(factor(probs &gt; 0.5, levels = c(&quot;FALSE&quot;, &quot;TRUE&quot;)), 
        factor(truth, levels = c(0, 1)))
    acc = sum(diag(tab))/sum(tab)
    sens = tab[2, 2]/colSums(tab)[2]
    spec = tab[1, 1]/colSums(tab)[1]
    ppv = tab[2, 2]/rowSums(tab)[2]
    f1 = 2 * (sens * ppv)/(sens + ppv)
    
    # CALCULATE EXACT AUC
    ord &lt;- order(probs, decreasing = TRUE)
    probs &lt;- probs[ord]
    truth &lt;- truth[ord]
    
    TPR = cumsum(truth)/max(1, sum(truth))
    FPR = cumsum(!truth)/max(1, sum(!truth))
    
    dup &lt;- c(probs[-1] &gt;= probs[-length(probs)], FALSE)
    TPR &lt;- c(0, TPR[!dup], 1)
    FPR &lt;- c(0, FPR[!dup], 1)
    n &lt;- length(TPR)
    auc &lt;- sum(((TPR[-1] + TPR[-n])/2) * (FPR[-1] - FPR[-n]))
    
    data.frame(acc, sens, spec, ppv, f1, auc)
}

k = 10
testdata &lt;- newdata %&gt;% mutate(PositionPF = ifelse(newdata$Position == 
    &quot;PF&quot;, 1, 0), TeamHOU = ifelse(newdata$Team == &quot;HOU&quot;, 1, 0), 
    TeamORL = ifelse(newdata$Team == &quot;ORL&quot;, 1, 0))
folds &lt;- ntile(1:nrow(testdata), n = 10)
diags &lt;- NULL
for (i in 1:k) {
    train &lt;- testdata[folds != i, ]  #create training set (all but fold i)
    test &lt;- testdata[folds == i, ]  #create test set (just fold i)
    truth &lt;- test$RankTop  #save truth labels from fold i
    
    fit &lt;- glm(RankTop ~ PositionPF + TeamHOU + TeamORL + Cash.Earned + 
        Cash.Earned.Per.Game, data = train, family = &quot;binomial&quot;)
    
    probs &lt;- predict(fit, newdata = test, type = &quot;response&quot;)
    
    diags &lt;- rbind(diags, class_diag(probs, truth))
}
diags %&gt;% summarize_all(mean)</code></pre>
<pre><code>##         acc sens spec       ppv  f1  auc
## 1 0.7566667  NaN  NaN 0.5666667 NaN 0.57</code></pre>
<h4>
<p>After running the 10-fold CV on the lasso variables, the AUC is 0.57 and the accuracy is 0.7566667, which differs from the model above.</p>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/docs.min.js"></script>
<script src="/js/main.js"></script>

<script src="/js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
